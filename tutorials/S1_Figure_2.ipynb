{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplimental 1: Labeling Function vs. Majority Vote\n",
    "This is the illustrative example used in Figure 2 of the Trove paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00010941123729693339\n",
      "0.0001338811595505871\n",
      "0.38824098106324595\n",
      "0.9998885791761051\n",
      "0.9956095834084472\n",
      "0.9956095834084472\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from snorkel.labeling.model.label_model import LabelModel\n",
    "\n",
    "X = ['risk','factor','for','diabetes','type','2']\n",
    "Y = [0,0,0,1,1,1]\n",
    "\n",
    "# label matrix \\Lambda (words x labeling functions)\n",
    "L = [\n",
    "    [-1, 0, 0, 0], # risk\n",
    "    [ 0, 0, 0, 0], # factor\n",
    "    [-1,-1,-1, 0], # for\n",
    "    [ 1, 1, 1,-1], # diabetes\n",
    "    [ 0, 1, 1, 0], # type\n",
    "    [ 0, 1, 1, 0], # 2\n",
    "]\n",
    "L = np.array(L)\n",
    "\n",
    "# labeling function names (terminolgies)\n",
    "lf_names = ['MTH', 'CHV', 'LNC', 'SNOMEDCT']\n",
    "\n",
    "# majority vote\n",
    "Y_mv = mode(L, axis=1)\n",
    "Y_mv[Y_mv == -1] = 0\n",
    "\n",
    "# data programming\n",
    "model = LabelModel(cardinality=2, verbose=True)\n",
    "model.fit(L, seed=100, n_epochs=100)\n",
    "Y_hat = model.predict_proba(L)\n",
    "\n",
    "for y in Y:\n",
    "    print(y[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learned Labeling Function Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LF weights (accuracies)\n",
      "[0.61711445 1.         1.         0.60000001]\n",
      "Conditional probs table\n",
      "[[[0.47450089 0.06187344]\n",
      "  [0.51549911 0.63080639]\n",
      "  [0.01       0.30732015]]\n",
      "\n",
      " [[0.18073374 0.0039503 ]\n",
      "  [0.76156282 0.01      ]\n",
      "  [0.05770345 0.98604971]]\n",
      "\n",
      " [[0.18073374 0.0039503 ]\n",
      "  [0.76156282 0.01      ]\n",
      "  [0.05770345 0.98604971]]\n",
      "\n",
      " [[0.         0.36171573]\n",
      "  [0.99000001 0.62828428]\n",
      "  [0.01       0.01      ]]]\n"
     ]
    }
   ],
   "source": [
    "w = model.get_weights()\n",
    "print(\"Loaded LF weights (accuracies)\")\n",
    "print(w)\n",
    "\n",
    "print(\"Conditional probs table\")\n",
    "cprobs = model.get_conditional_probs()\n",
    "print(cprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
