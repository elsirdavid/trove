{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Weakly Supervised Named Entity Recognition (NER)\n",
    "\n",
    "We'll use the public [BioCreative V Chemical Disease Relation](https://biocreative.bioinformatics.udel.edu/tasks/biocreative-v/track-3-cdr/) (BC5CDR) dataset, focusing on Chemical entities. \n",
    "\n",
    "See `../applications/BC5CDR/` for the complete labeling function set used in our paper. \n",
    "\n",
    "## Installation Instructions\n",
    "\n",
    "- Trove requires access to the [Unified Medical Language System](https://www.nlm.nih.gov/research/umls/licensedcontent/umlsknowledgesources.html) (UMLS) which is available after signing up for an account. If you already have a UMLS database instance, you can extract RRF files by running `dump_umls_rrfs.sh`\n",
    "- Unzip the preprocessed BioCreative V CDR chemical dataset `bc5cdr.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../trove')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Unlabeled Data & Define Entity Classes\n",
    "\n",
    "### A. Load Preprocessed Documents\n",
    "This notebook assumes documents have already been preprocessed for sentence boundary detection and dumped into JSON format. See `preprocessing/README.md` for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import transformers\n",
    "from trove.dataloaders import load_json_dataset\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
    "\n",
    "data_dir = \"bc5cdr/\"\n",
    "dataset = {\n",
    "    split : load_json_dataset(f'{data_dir}/{split}.cdr.chemical.json', tokenizer)\n",
    "    for split in ['train', 'dev', 'test']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B. Define Entity Categories\n",
    "In popular biomedical annotators such as [NCBO BioPortal](https://bioportal.bioontology.org/annotator), we configure the annotator by defining our entity\n",
    "Trove uses this same style of interface in an API form. For `CHEMICAL` tagging, we define an entity class consisting of [UMLS Semantic Network](https://semanticnetwork.nlm.nih.gov/) types mapped to $\\{0,1\\}$. The semantic network defines 127 concept categories called _Semantic Types_ (e.g., Disease or Syndrome , Medical Device) which are mappable to 15 coarser-grained _Semantic Groups_ (e.g., Anatomy, Chemicals & Drugs, Disorders). \n",
    "\n",
    "We use the _Chemicals & Drugs_ (CHEM) semantic group as the basis of our positive class label $1$, removing some categories (e.g., Gene or Genome) that do not match the definition of chemical as outlined in the BC5CDR annotation guidelines. Non-chemical STYs define our negative class label $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the chemical entity definition\n",
    "entity_def = pd.read_csv('chemical_semantic_types.tsv', sep='\\t')\n",
    "class_map = {row.TUI:row.LABEL for row in entity_def.itertuples()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Labeling Sources\n",
    "### A. Unified Medical Language System (UMLS) Metathesaurus\n",
    "The UMLS Metathesaurus is a convenient source for deriving labels, since it provides over 200 source vocabularies (terminologies) with consistent entity categorization provided by the UMLS Semantic Network.\n",
    "\n",
    "The first time this is run, Trove requires access to the source RRF files `{MRSTY.RRF, MRSAB.RRF, MRCONSO.RRF}` originally used to create the database instance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trove.labelers.umls import UMLS\n",
    "\n",
    "# uncommenting this line will reset the Trove UMLS cache\n",
    "#UMLS.reset()\n",
    "\n",
    "# initialize UMLS\n",
    "backend = 'pandas'\n",
    "if not UMLS.is_initalized(backend=backend):\n",
    "    UMLS.init_from_rrfs(indir=\"/users/fries/desktop/RRFs\", backend=backend)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply some minimal preprocessing to each source vocabularies term set, as outlined in the Trove paper. The most important settings are:\n",
    "- `SmartLowercase()`, a string matching heuristic for preserving likely abbreviations and acronyms\n",
    "- `min_char_len`, `filter_rgx`, filters for terms that are single characters or numbers  \n",
    "\n",
    "Other choices are largely for speed purposes, such as restricting the max token length used for string matching. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from trove.transforms import SmartLowercase\n",
    "\n",
    "# options for filtering terms\n",
    "config = {\n",
    "    \"type_mapping\"  : \"TUI\",  # TUI = semantic types, CUI = concept ids\n",
    "    'min_char_len'  : 2,\n",
    "    'max_tok_len'   : 6,\n",
    "    'min_dict_size' : 500,\n",
    "    'stopwords'     : None,\n",
    "    'transforms'    : [SmartLowercase()],\n",
    "    'languages'     : {\"ENG\"},\n",
    "    'filter_sabs'   : {\"SNOMEDCT_VET\"},\n",
    "    'filter_rgx'    : r'''^[-+]*[0-9]+([.][0-9]+)*$'''  # filter numbers\n",
    "}\n",
    "   \n",
    "umls = UMLS(backend=backend, **config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. ADAM Biomedical Abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "def map_entity_classes(dictionary, class_map):\n",
    "    \"\"\"\n",
    "    Given a dictionary, create the term\n",
    "    \"\"\"\n",
    "    k = len([y for y in set(class_map.values()) if y != -1])\n",
    "    ontology = {}\n",
    "    for term in dictionary:\n",
    "        proba = np.zeros(shape=k).astype(np.float32)\n",
    "        for cls in dictionary[term]:\n",
    "            idx = class_map[cls]\n",
    "            proba[idx] += 1\n",
    "        ontology[term] = proba / np.sum(proba)\n",
    "    return ontology\n",
    "\n",
    "# These are the top 10 ontologies as ranked by term overlap with the BC5CDR training set\n",
    "terminologies = ['CHV', 'SNOMEDCT_US', 'NCI', 'MSH']\n",
    "\n",
    "ontologies = {\n",
    "    sab : map_entity_classes(umls.terminologies[sab], class_map)\n",
    "    for sab in terminologies\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Sequence Labeling Functions\n",
    "### A. Guideline Labeling Functions\n",
    "\n",
    "Annotation guidelines, the instructions provided to domain experts when labeling training data, can have a big impact on the generalizability of named enity classifiers. These instructions include seeminly simple choices such as whether to include determiners in entity spans (\"the XXX\") or more complex tagging choices like not labeling negated mentions of drugs. These choices are baked into the dataset and expensive to change. \n",
    "\n",
    "With weak supervision, many of these annotation assumptions can encoded as labeling functions, making training set changes faster, more flexible, and lower cost. For our `Chemical` labeling functions, we use the instructions provided [here](https://biocreative.bioinformatics.udel.edu/media/store/files/2015/bc5_CDR_data_guidelines.pdf) (pages 5-6) to create small dictionaries encoding some of these guidelines. Note that these can be easily expanded on, and in some cases complex rules (e.g., not annotating polypeptides with more than 15 amino acids) can be coupled with richer structured resources to create more sophisticated rules. \n",
    "\n",
    "We also fine it useful to include labeling functions that exclude numbers and punctuation tokens, another common flag in online biomedical annotators. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trove.labelers.labeling import (\n",
    "    OntologyLabelingFunction,\n",
    "    DictionaryLabelingFunction, \n",
    "    RegexEachLabelingFunction\n",
    ")\n",
    "\n",
    "MAX_NGRAMS = 8\n",
    "\n",
    "# load our guideline dictionaries\n",
    "df = pd.read_csv('data/bc5cdr_guidelines.tsv', sep='\\t')\n",
    "guidelines = {\n",
    "    t:np.array([0.,1.]) if y==1 else np.array([1.,0.]) \n",
    "    for t,y in zip(df.TERM, df.TERM)\n",
    "}\n",
    "\n",
    "# use guideline negation examples as an additional stopword list\n",
    "stopwords = {t:0 for t in df[df.LABEL==0].TERM}\n",
    "\n",
    "guideline_lfs = [\n",
    "    OntologyLabelingFunction('LF_guidelines', guidelines, max_ngrams=MAX_NGRAMS),\n",
    "    DictionaryLabelingFunction('LF_punct', set('!\"#$%&*+,./:;<=>?@[\\\\]^_`{|}~'), 2),\n",
    "    RegexEachLabelingFunction('LF_numbers_rgx', [r'''^[-]*[1-9]+[0-9]*([.][0-9]+)*$'''], 2)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Semantic Type Labeling Functions\n",
    "\n",
    "The bulk of our supervision comes from structured knowedge sources such as medical ontologies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_lfs = [\n",
    "    OntologyLabelingFunction(\n",
    "        f'LF_{name}', \n",
    "        ontologies[name], \n",
    "        max_ngrams=MAX_NGRAMS, \n",
    "        stopwords=stopwords\n",
    "    )\n",
    "    for name in ontologies\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. SynSet Labeling Functions\n",
    "\n",
    "For biomedical concepts, abbreviations and acronymns (more generally \"short forms\") are a large source of ambiguity. \n",
    "These can be ambiguous to human readers as well, so authors of PubMed abstract typically define ambiguous terms when they are introduced in text. We can take adavantage of this redundancy to both handle ambiguous mentions and identify out-of-ontology short forms using classic text mining techniques such as the [Schwartz-Hearst algorithm](https://psb.stanford.edu/psb-online/proceedings/psb03/schwartz.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD\n",
    "\n",
    "# synset_lfs = [\n",
    "#     SchwartzHearstLabelingFunction('LF_umls_abbrvs_1', class_dictionaries[1], 1, stopwords=stopwords),\n",
    "#     SchwartzHearstLabelingFunction('LF_umls_abbrvs_2', class_dictionaries[2], 2),\n",
    "#     SynSetLabelingFunction('LF_specialist_synset_1', specialist_1, 1, stopwords=stopwords),\n",
    "#     SynSetLabelingFunction('LF_specialist_synset_2', specialist_2, 2)\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Task-specific Labeling Functions\n",
    "\n",
    "Ontology-based labeling functions can do suprisingly well on their own, but we can get more performance gains by adding custom labeling functions. For this demo, we focus on simple rules that are easy to create via data exploration but any existing rule-based model can be transformed into a labeling function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_specific_lfs = []\n",
    "\n",
    "# We noticed parentheses were causing errors, so this identifies negative examples, e.g. (n=100), (10%)\n",
    "parens_rgxs = [\n",
    "    r'''[(](P|p|n)\\s*([><=]+|(less|great)(er)*)|(ml|mg|kg|g|(year|day|month)[s]*)[)]|[(][0-9]+[%][)]'''\n",
    "]\n",
    "parens_rgxs = [re.compile(rgx, re.I) for rgx in parens_rgxs]\n",
    "task_specific_lfs.append(RegexLabelingFunction('LF_parentheses_rgx', parens_rgxs, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = guideline_lfs + ontology_lfs + synset_lfs + task_specific_lfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Construct the Label Matrix $\\Lambda$\n",
    "### A. Apply Sequence Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import itertools\n",
    "from trove.labelers.core import SequenceLabelingServer\n",
    "\n",
    "X_sents = [\n",
    "    dataset['train'].sentences,\n",
    "    dataset['dev'].sentences,\n",
    "    dataset['test'].sentences,\n",
    "]\n",
    "\n",
    "labeler = SequenceLabelingServer(num_workers=4)\n",
    "L_sents = labeler.apply(lfs, X_sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "splits = ['train', 'dev', 'test']\n",
    "tag2idx = {'O':2, 'I-Chemical':1}\n",
    "\n",
    "X_words = [\n",
    "    np.array(list(itertools.chain.from_iterable([s.words for s in X_sents[i]]))) \n",
    "    for i,name in enumerate(splits)\n",
    "]\n",
    "\n",
    "X_seq_lens = [\n",
    "    np.array([len(s.words) for s in X_sents[i]])\n",
    "    for i,name in enumerate(splits)\n",
    "]\n",
    "\n",
    "X_doc_seq_lens = [  \n",
    "    np.array([len(doc.sentences) for doc in dataset[name].documents]) \n",
    "    for i,name in enumerate(splits)\n",
    "]\n",
    "\n",
    "Y_words = [\n",
    "    [dataset['train'].tagged(i)[-1] for i in range(len(dataset['train']))],\n",
    "    [dataset['dev'].tagged(i)[-1] for i in range(len(dataset['dev']))],\n",
    "    [dataset['test'].tagged(i)[-1] for i in range(len(dataset['test']))],\n",
    "]\n",
    "\n",
    "Y_words[0] = np.array([tag2idx[t] for t in list(itertools.chain.from_iterable(Y_words[0]))])\n",
    "Y_words[1] = np.array([tag2idx[t] for t in list(itertools.chain.from_iterable(Y_words[1]))])\n",
    "Y_words[2] = np.array([tag2idx[t] for t in list(itertools.chain.from_iterable(Y_words[2]))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Build the Label Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from scipy.sparse import dok_matrix, vstack, csr_matrix\n",
    "\n",
    "def create_word_lf_mat(Xs, Ls, num_lfs):\n",
    "    \"\"\"\n",
    "    Create word-level LF matrix from LFs indexed by sentence/word\n",
    "    0 words X lfs\n",
    "    1 words X lfs\n",
    "    2 words X lfs\n",
    "    ...\n",
    "    \n",
    "    \"\"\"\n",
    "    Yws = []\n",
    "    for sent_i in range(len(Xs)):\n",
    "        ys = dok_matrix((len(Xs[sent_i].words), num_lfs))\n",
    "        for lf_i in range(num_lfs):\n",
    "            for word_i,y in Ls[sent_i][lf_i].items():\n",
    "                ys[word_i, lf_i] = y\n",
    "        Yws.append(ys)\n",
    "    return csr_matrix(vstack(Yws))\n",
    "\n",
    "L_words = [\n",
    "    create_word_lf_mat(X_sents[0], L_sents[0], len(lfs)),\n",
    "    create_word_lf_mat(X_sents[1], L_sents[1], len(lfs)),\n",
    "    create_word_lf_mat(X_sents[2], L_sents[2], len(lfs)),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Inspect Labeling Function Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trove.metrics.analysis import lf_summary\n",
    "\n",
    "lf_summary(L_words[0], Y=Y_words[0], lf_names=['CHV', 'SNOMEDCT_US', 'NCI', 'MSH'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Label Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trove uses a different internal mapping for labeling function abstains\n",
    "def convert_label_matrix(L):\n",
    "    # abstain is -1\n",
    "    # negative is 0\n",
    "    L = L.toarray().copy()\n",
    "    L[L == 0] = -1\n",
    "    L[L == 2] = 0\n",
    "    return L\n",
    "\n",
    "L_words_hat = [\n",
    "    convert_label_matrix(L_words[0]),\n",
    "    convert_label_matrix(L_words[1]),\n",
    "    convert_label_matrix(L_words[2])\n",
    "]\n",
    "\n",
    "Y_words_hat = [\n",
    "    np.array([0 if y == 2 else 1 for y in Y_words[0]]),\n",
    "    np.array([0 if y == 2 else 1 for y in Y_words[1]]),\n",
    "    np.array([0 if y == 2 else 1 for y in Y_words[2]])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [0.01, 0.005, 0.001, 0.0001],\n",
    "    'l2': [0.001, 0.0001],\n",
    "    'n_epochs': [50, 100, 200, 600, 700, 1000],\n",
    "    'prec_init': [0.6, 0.7, 0.8, 0.9],\n",
    "    'optimizer': [\"adamax\"], \n",
    "    'lr_scheduler': ['constant']\n",
    "}\n",
    "\n",
    "model_class_init = {\n",
    "    'cardinality': 2, \n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "n_model_search = 50\n",
    "num_hyperparams = functools.reduce(lambda x,y:x*y, [len(x) for x in param_grid.values()])\n",
    "print(\"Hyperparamater Search Space:\", num_hyperparams)\n",
    "\n",
    "label_model, best_config = grid_search(LabelModel, \n",
    "                                       model_class_init, \n",
    "                                       param_grid,\n",
    "                                       train = (L_train, Y_train, train_seq_lens),\n",
    "                                       dev = (L_dev, Y_dev, dev_seq_lens),\n",
    "                                       n_model_search=n_model_search, \n",
    "                                       val_metric='f1', \n",
    "                                       seq_eval=True,\n",
    "                                       seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trove.analysis.error_analysis import get_coverage, eval_label_model\n",
    "\n",
    "for i in range(3):\n",
    "    get_coverage(L_words_hat[i], Y_words_hat[i])\n",
    "    print(\"IO Tag Format\")\n",
    "    eval_label_model(label_model, L_words_hat[i], Y_words_hat[i], X_seq_lens[i])\n",
    "    print(\"BIO Tag Format\")\n",
    "    eval_label_model(label_model, L_words_hat[i], Y_words_gold_hat[i], X_seq_lens[i])\n",
    "    print('------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Proba Conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
